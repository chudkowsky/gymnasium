{
  "comment": "PPO training with parallel game collection (8 worker processes)",
  "training": {
    "total_steps": 500000,
    "steps_per_update": 4096,
    "log_interval": 1,
    "checkpoint_interval": 5,
    "device": "cuda",
    "seed": 42
  },
  "ppo": {
    "learning_rate": 1e-3,
    "n_epochs": 8,
    "batch_size": 256,
    "clip_ratio": 0.2,
    "entropy_coef": 0.02,
    "value_coef": 0.5,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "max_grad_norm": 0.5
  },
  "rollout": {
    "num_episodes_per_update": 64,
    "num_envs": 1,
    "max_episode_length": 200,
    "parallel": {
      "enabled": true,
      "num_workers": 8,
      "comment": "Number of worker processes. Adjust based on available CPU cores."
    },
    "shaped_reward": {
      "enabled": false
    }
  },
  "opponent_pool": {
    "types": ["random", "stockfish"],
    "sampling": "uniform",
    "comment": "Types: 'random', 'stockfish', 'snapshot'.",
    "stockfish": {
      "enabled": true,
      "depth": 7,
      "movetime_ms": null,
      "fraction": 0.5,
      "comment": "Set enabled=true to include Stockfish. movetime_ms overrides depth if set."
    }
  },
  "checkpoints": {
    "pretrained_path": "data/checkpoints/pretrained.pth",
    "trained_output_dir": "data/checkpoints",
    "save_format": "trained_ppo_step_{step}.pth"
  }
}
