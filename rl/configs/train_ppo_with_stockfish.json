{
  "comment": "PPO training configuration with Stockfish opponent",
  "training": {
    "total_steps": 100000,
    "steps_per_update": 2048,
    "log_interval": 100,
    "checkpoint_interval": 1000,
    "device": "cpu",
    "seed": 42
  },
  "ppo": {
    "learning_rate": 3e-4,
    "n_epochs": 3,
    "batch_size": 128,
    "clip_ratio": 0.2,
    "entropy_coef": 0.01,
    "value_coef": 0.5,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "max_grad_norm": 0.5
  },
  "rollout": {
    "num_episodes_per_update": 32,
    "num_envs": 1,
    "max_episode_length": 300
  },
  "opponent_pool": {
    "types": ["random", "stockfish"],
    "sampling": "uniform",
    "comment": "Includes both random and Stockfish opponents for curriculum learning",
    "stockfish": {
      "enabled": true,
      "depth": 7,
      "movetime_ms": null,
      "fraction": 0.5,
      "comment": "depth=10 balances strength vs speed. Adjust for CPU/GPU availability."
    }
  },
  "checkpoints": {
    "pretrained_path": "data/checkpoints/pretrained.pth",
    "trained_output_dir": "data/checkpoints",
    "save_format": "trained_ppo_step_{step}.pth"
  }
}
